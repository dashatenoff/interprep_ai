# agents/coordinator.py
import json
import sys
from pathlib import Path
from pydantic import BaseModel
from gigachat import GigaChat
from dotenv import load_dotenv
import os
from typing import Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ RAG
sys.path.append(str(Path(__file__).resolve().parent.parent))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º RAG (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫)
try:
    from rag.retriever import retrieve_context

    RAG_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  RAG –º–æ–¥—É–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω. Coordinator –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.")
    RAG_AVAILABLE = False


    def retrieve_context(query: str, k: int = 4) -> list:
        return []

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω –∏–∑ .env
load_dotenv()


# ===============================
#  –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
# ===============================
class RouteResult(BaseModel):
    agent: str
    context: str
    metadata: dict
    confidence: float
    suggested_topics: Optional[list] = None
    rag_context_used: Optional[bool] = False


# ===============================
#  –ö–ª–∞—Å—Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞ —Å RAG
# ===============================
class CoordinatorAgent:
    def __init__(self, use_rag: bool = True):
        load_dotenv()
        self.client_secret = os.getenv("GIGACHAT_CLIENT_SECRET")
        if not self.client_secret:
            raise ValueError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω GIGACHAT_CLIENT_SECRET –≤ .env")

        self.llm = GigaChat(
            credentials=self.client_secret,
            verify_ssl_certs=False,
            model="GigaChat"
        )
        self.use_rag = use_rag and RAG_AVAILABLE

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        self.prompt_without_rag = """
–¢—ã ‚Äî –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä (Coordinator) –¥–ª—è –±–æ—Ç–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è–º.

–ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{user_context}

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_text}

–î–û–°–¢–£–ü–ù–´–ï –ê–ì–ï–ù–¢–´:
1. INTERVIEWER ‚Äî –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é, –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤, mock –∏–Ω—Ç–µ—Ä–≤—å—é
2. ASSESSOR ‚Äî –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∑–Ω–∞–Ω–∏–π, —Ç–µ—Å—Ç–æ–≤, –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —É—Ä–æ–≤–Ω—è, —Å–æ–≤–µ—Ç—ã –ø–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è–º, –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã
3. PLANNER ‚Äî –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–ª–∞–Ω–æ–≤ —Ä–∞–∑–≤–∏—Ç–∏—è, roadmap, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
4. REVIEWER ‚Äî –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞ –∫–æ–¥–∞, —Ä–µ–≤—å—é —Ä–µ—à–µ–Ω–∏–π –∑–∞–¥–∞—á

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "agent": "–ù–ê–ó–í–ê–ù–ò–ï_–ê–ì–ï–ù–¢–ê",
  "context": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞",
  "metadata": {{
    "topic": "–æ—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞",
    "urgency": "high/medium/low",
    "complexity": "beginner/intermediate/advanced",
    "experience_level": "junior/middle/senior"
  }},
  "confidence": 0.95,
  "suggested_topics": ["—Ç–µ–º–∞1", "—Ç–µ–º–∞2"]
}}
"""

        self.prompt_with_rag = """
–¢—ã ‚Äî —É–º–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è—Ö.

–ö–û–ù–¢–ï–ö–°–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{user_context}

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Ç–µ–º—ã):
{rag_context}

–û–ø—Ä–µ–¥–µ–ª–∏ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–î–û–°–¢–£–ü–ù–´–ï –ê–ì–ï–ù–¢–´:
1. INTERVIEWER ‚Äî –≤–æ–ø—Ä–æ—Å—ã —Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π, mock –∏–Ω—Ç–µ—Ä–≤—å—é, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã
2. ASSESSOR ‚Äî –æ—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è, –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π, —Å–æ–≤–µ—Ç—ã –ø–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è–º, –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã
3. PLANNER ‚Äî –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è, roadmap, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ
4. REVIEWER ‚Äî —Ä–∞–∑–±–æ—Ä –∫–æ–¥–∞, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏–π, code review

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_text}

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "agent": "–ù–ê–ó–í–ê–ù–ò–ï_–ê–ì–ï–ù–¢–ê",
  "context": "–∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞",
  "metadata": {{
    "primary_topic": "–≥–ª–∞–≤–Ω–∞—è —Ç–µ–º–∞",
    "secondary_topics": ["–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–º—ã"],
    "interview_type": "technical/behavioral/system_design",
    "experience_level": "junior/middle/senior"
  }},
  "confidence": 0.0-1.0,
  "suggested_topics": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ–º—ã –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"],
  "rag_context_used": true
}}
"""

    def _get_rag_context_for_routing(self, user_text: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è)"""
        if not self.use_rag:
            return ""

        try:
            context_chunks = retrieve_context(user_text, k=2)

            if not context_chunks:
                keywords = self._extract_keywords(user_text)
                for keyword in keywords[:3]:
                    keyword_context = retrieve_context(keyword, k=1)
                    context_chunks.extend(keyword_context)

            if context_chunks:
                formatted_context = "\n".join([
                    f"üìö –ö–æ–Ω—Ç–µ–∫—Å—Ç {i + 1}: {chunk[:200]}..."
                    for i, chunk in enumerate(context_chunks)
                ])
                return formatted_context
            return "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π."

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ RAG –≤ Coordinator: {e}")
            return ""

    def _extract_keywords(self, text: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è)"""
        tech_keywords = [
            "python", "java", "javascript", "–∞–ª–≥–æ—Ä–∏—Ç–º", "–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö", "sql",
            "–æ–æ–ø", "–∏–Ω—Ç–µ—Ä–≤—å—é", "—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ", "–æ—Ü–µ–Ω–∫–∞", "–ø–ª–∞–Ω", "–∫–æ–¥",
            "junior", "middle", "senior", "backend", "frontend", "devops",
            "docker", "kubernetes", "–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å", "api", "rest", "graphql"
        ]

        text_lower = text.lower()
        found_keywords = []

        for keyword in tech_keywords:
            if keyword in text_lower:
                found_keywords.append(keyword)

        return found_keywords[:5]

    def route(self, user_text: str, user_context: dict = None) -> RouteResult:
        """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG (—É–ª—É—á—à–µ–Ω–Ω–∞—è)"""

        if user_context is None:
            user_context = {}

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        context_parts = []
        if 'level' in user_context:
            context_parts.append(f"–£—Ä–æ–≤–µ–Ω—å: {user_context['level']}")
        if 'track' in user_context:
            context_parts.append(f"–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {user_context['track']}")
        if 'current_mode' in user_context:
            context_parts.append(f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {user_context['current_mode']}")

        user_context_str = "\n".join(context_parts) if context_parts else "–ù–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG
        rag_context = self._get_rag_context_for_routing(user_text)

        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç
        if self.use_rag and rag_context and "–ö–æ–Ω—Ç–µ–∫—Å—Ç" in rag_context:
            prompt = self.prompt_with_rag.format(
                user_context=user_context_str,
                user_text=user_text,
                rag_context=rag_context
            )
            rag_context_used = True
        else:
            prompt = self.prompt_without_rag.format(
                user_context=user_context_str,
                user_text=user_text
            )
            rag_context_used = False

        if user_text.lower().startswith(('/plan', '–ø–ª–∞–Ω', '–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ', 'learning plan')):
            # –Ø–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º PLANNER –¥–ª—è —Ç–∞–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            return RouteResult(
                agent="PLANNER",
                context="–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –æ–±—É—á–µ–Ω–∏—è",
                metadata={"topic": "planning", "urgency": "medium"},
                confidence=0.95,
                suggested_topics=["–æ–±—É—á–µ–Ω–∏–µ", "—Ä–∞–∑–≤–∏—Ç–∏–µ"],
                rag_context_used=False
            )

        try:
            response = self.llm.chat(prompt)
            text = response.choices[0].message.content.strip()

            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            text = self._clean_response(text)

            # –î–û–ë–ê–í–õ–ï–ù–û: –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ JSON
            text = self._fix_json_problems(text)

            # –î–û–ë–ê–í–õ–ï–ù–û: –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –ø–æ–ª—É—á–∞–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            print(f"üì• Coordinator –ø–æ–ª—É—á–∏–ª: {text[:100]}...")

            # –ü–∞—Ä—Å–∏–º JSON
            data = json.loads(text)

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –∞–≥–µ–Ω—Ç–∞
            agent_name = data.get("agent", "INTERVIEWER").upper()
            agent_name = self._normalize_agent_name(agent_name)

            return RouteResult(
                agent=agent_name,
                context=data.get("context", "–û–±—â–∏–π –∑–∞–ø—Ä–æ—Å"),
                metadata=data.get("metadata", {}),
                confidence=min(max(data.get("confidence", 0.5), 0.0), 1.0),
                suggested_topics=data.get("suggested_topics", []),
                rag_context_used=rag_context_used
            )

        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≤ Coordinator: {e}")
            print(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {text[:200] if 'text' in locals() else '–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞'}")

            # –î–û–ë–ê–í–õ–ï–ù–û: –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å JSON
            try:
                data = self._recover_json(text)
                agent_name = data.get("agent", "INTERVIEWER").upper()
                agent_name = self._normalize_agent_name(agent_name)

                return RouteResult(
                    agent=agent_name,
                    context=data.get("context", "–û–±—â–∏–π –∑–∞–ø—Ä–æ—Å"),
                    metadata=data.get("metadata", {}),
                    confidence=data.get("confidence", 0.3),
                    suggested_topics=data.get("suggested_topics", []),
                    rag_context_used=rag_context_used
                )
            except:
                # –ï—Å–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
                agent = self._fallback_agent_detection(user_text)

                return RouteResult(
                    agent=agent,
                    context="–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ fallback –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ",
                    metadata={"error": str(e), "fallback": True},
                    confidence=0.3,
                    rag_context_used=rag_context_used
                )

        except Exception as e:
            print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –≤ Coordinator.route: {e}")

            return RouteResult(
                agent="INTERVIEWER",
                context=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)[:100]}",
                metadata={"error": str(e)},
                confidence=0.1,
                rag_context_used=rag_context_used
            )

    def _clean_response(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç Markdown –∏ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        # –£–¥–∞–ª—è–µ–º Markdown –±–ª–æ–∫–∏
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text:
            text = text.split("```")[1].split("```")[0].strip() if text.count("```") >= 2 else text.strip("`").strip()

        # –£–¥–∞–ª—è–µ–º –ø–æ—è—Å–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ JSON
        import re
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            text = json_match.group()

        return text.strip()

    def _fallback_agent_detection(self, user_text: str) -> str:
        """Fallback –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø"""
        text_lower = user_text.lower()

        keyword_mapping = {
            "interviewer": ["–∏–Ω—Ç–µ—Ä–≤—å—é", "–æ–ø—Ä–æ—Å", "–≤–æ–ø—Ä–æ—Å", "–∑–∞–¥–∞–π", "–ø—Ä–æ–≤–µ–¥–∏", "mock",
                            "—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ", "interview", "—Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏", "—ç–∫–∑–∞–º–µ–Ω"],
            "assessor": ["–æ—Ü–µ–Ω", "—Ç–µ—Å—Ç", "–ø—Ä–æ–≤–µ—Ä", "—É—Ä–æ–≤–µ–Ω—å", "–Ω–∞—Å–∫–æ–ª—å–∫–æ", "–¥–∏–∞–≥–Ω–æ—Å",
                         "—Å–∏–ª—å–Ω—ã–µ", "—Å–ª–∞–±—ã–µ", "–∑–Ω–∞–Ω–∏—è", "—Å–∫–∏–ª–ª—ã", "–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏"],
            "planner": ["–ø–ª–∞–Ω", "roadmap", "–ø—Ä–æ–≥—Ä–∞–º–º–∞", "—Ä–∞—Å–ø–∏—Å–∞–Ω", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü",
                        "–∏–∑—É—á", "–æ—Å–≤–æ", "–Ω–∞—É—á", "–ø–æ–¥–≥–æ—Ç–æ–≤–∫", "–æ–±—É—á–µ–Ω",
                        "–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä", "docker", "kubernetes",
                        "—Ö–æ—á—É –∏–∑—É—á–∞—Ç—å", "—Ö–æ—á—É –Ω–∞—É—á–∏—Ç—å—Å—è", "—Ö–æ—á—É –æ—Å–≤–æ–∏—Ç—å"],
            "reviewer": ["–∫–æ–¥", "—Ä–µ—à–µ–Ω–∏–µ", "–∑–∞–¥–∞—á–∞", "–æ–ø—Ç–∏–º–∏–∑", "—Ä–µ–≤—å—é", "—Ä–∞–∑–±–æ—Ä",
                         "–∞–ª–≥–æ—Ä–∏—Ç–º", "—Å–∏–Ω—Ç–∞–∫—Å–∏—Å", "–ø–∞—Ç—Ç–µ—Ä–Ω", "—Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥"],
            "helper": ["—Å–æ–≤–µ—Ç", "–∫–∞–∫", "–ø–æ–¥–≥–æ—Ç–æ–≤", "—á—Ç–æ –¥–µ–ª–∞—Ç—å", "–ø–æ–º–æ—â—å",
                       "–æ–±—ä—è—Å–Ω–∏", "—Ä–∞—Å—Å–∫–∞–∂–∏", "—á—Ç–æ —Ç–∞–∫–æ–µ", "–∑–∞—á–µ–º"]
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –í–°–ï –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for agent, keywords in keyword_mapping.items():
            if any(keyword in text_lower for keyword in keywords):
                return agent.upper()

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –µ—Å–ª–∏ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ, —Ç–æ —Å–ø—Ä–∞—à–∏–≤–∞–µ–º —É—Ç–æ—á–Ω–µ–Ω–∏–µ
        return "ASK_CLARIFICATION"

    def route_with_history(self, user_text: str, history: list = None,
                           user_context: dict = None) -> RouteResult:
        """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ (—É–ª—É—á—à–µ–Ω–Ω–∞—è)"""
        if not history:
            return self.route(user_text, user_context)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
        history_context = "\n".join([
            f"{'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å' if msg.get('role') == 'user' else '–ë–æ—Ç'}: {msg.get('content', '')[:100]}..."
            for msg in history[-3:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
        ])

        # –ö–ª—é—á–µ–≤–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –±—ã–ª–∞ –∫–æ–º–∞–Ω–¥–∞ /plan
        # —Ç–æ —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - —ç—Ç–æ —Ç–µ–º–∞ –¥–ª—è –ø–ª–∞–Ω–∞!
        for msg in history[-2:]:  # –°–º–æ—Ç—Ä–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–æ–æ–±—â–µ–Ω–∏—è
            if msg.get('role') == 'bot' and '/plan' in msg.get('content', ''):
                # –ï—Å–ª–∏ –±–æ—Ç —Ç–æ–ª—å–∫–æ —á—Ç–æ –æ—Ç–ø—Ä–∞–≤–∏–ª –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ç–µ–º—É –ø–ª–∞–Ω–∞
                # –∑–Ω–∞—á–∏—Ç —Å–ª–µ–¥—É—é—â–∏–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - —ç—Ç–æ —Ç–µ–º–∞ –¥–ª—è –ø–ª–∞–Ω–µ—Ä–∞!
                return RouteResult(
                    agent="PLANNER",
                    context=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª —Ç–µ–º—É –¥–ª—è –ø–ª–∞–Ω–∞ –æ–±—É—á–µ–Ω–∏—è: {user_text}",
                    confidence=0.9
                )

        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–∫–∞–∑–∞–ª —á—Ç–æ —Ö–æ—á–µ—Ç —á—Ç–æ-—Ç–æ –∏–∑—É—á–∏—Ç—å
        user_last_msg = next((msg for msg in reversed(history)
                              if msg.get('role') == 'user'), None)

        if user_last_msg:
            last_text = user_last_msg.get('content', '').lower()
            if any(word in last_text for word in ['–∏–∑—É—á', '–æ—Å–≤–æ', '–Ω–∞—É—á', '—Ö–æ—á—É –∏–∑—É—á–∞—Ç—å']):
                # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ–ª—å–∫–æ —á—Ç–æ —Å–∫–∞–∑–∞–ª —á—Ç–æ —Ö–æ—á–µ—Ç —á—Ç–æ-—Ç–æ –∏–∑—É—á–∏—Ç—å
                return RouteResult(
                    agent="PLANNER",
                    context=f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –∏–∑—É—á–∞—Ç—å —Ç–µ–º—É: {user_text}",
                    confidence=0.9
                )

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_context is None:
            user_context = {}

        full_context = {
            **user_context,
            "history_preview": history_context
        }

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π route —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        return self.route(
            user_text=f"{user_text} [–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏: {history_context[:50]}...]",
            user_context=full_context
        )

    def _fix_json_problems(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ JSON –æ—Ç GigaChat"""
        # 1. –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
        replacements = {
            '¬´': '"',
            '¬ª': '"',
            '‚Äú': '"',  # —É–º–Ω—ã–µ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ
            '‚Äù': '"',  # —É–º–Ω—ã–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ
            '‚Äò': "'",
            '‚Äô': "'",
            '\u201c': '"',  # Unicode –¥–ª—è —É–º–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫
            '\u201d': '"',
            '\u2018': "'",
            '\u2019': "'",
        }

        for wrong, correct in replacements.items():
            text = text.replace(wrong, correct)

        # 2. –£–¥–∞–ª—è–µ–º –Ω–µ–≤–∏–¥–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
        import re
        text = re.sub(r'[\x00-\x1F\x7F]', '', text)

        # 3. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—è—Ç—ã–µ –≤ –∫–æ–Ω—Ü–µ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ –º–∞—Å—Å–∏–≤–æ–≤
        text = re.sub(r',\s*}', '}', text)
        text = re.sub(r',\s*]', ']', text)

        return text

    def _recover_json(self, text: str) -> dict:
        """–ü—ã—Ç–∞–µ—Ç—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–ª–æ–º–∞–Ω–Ω—ã–π JSON"""
        import re

        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ —Ç–µ–∫—Å—Ç–µ
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            try:
                return json.loads(json_str)
            except:
                pass

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ JSON, –∏—â–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        result = {}

        # –ò—â–µ–º agent
        agent_match = re.search(r'"agent"\s*:\s*"([^"]+)"', text, re.IGNORECASE)
        if agent_match:
            result['agent'] = agent_match.group(1)

        # –ò—â–µ–º context
        context_match = re.search(r'"context"\s*:\s*"([^"]+)"', text, re.IGNORECASE)
        if context_match:
            result['context'] = context_match.group(1)

        # –ò—â–µ–º confidence
        confidence_match = re.search(r'"confidence"\s*:\s*([0-9.]+)', text, re.IGNORECASE)
        if confidence_match:
            try:
                result['confidence'] = float(confidence_match.group(1))
            except:
                result['confidence'] = 0.5

        # –î–æ–±–∞–≤–ª—è–µ–º metadata –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if 'metadata' not in result:
            result['metadata'] = {}

        return result

    def _normalize_agent_name(self, agent_name: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏–º—è –∞–≥–µ–Ω—Ç–∞"""
        agent_name = agent_name.upper()

        if "ASSESS" in agent_name:
            return "ASSESSOR"
        elif "INTERVIEW" in agent_name:
            return "INTERVIEWER"
        elif "PLAN" in agent_name:
            return "PLANNER"
        elif "REVIEW" in agent_name:
            return "REVIEWER"
        else:
            return agent_name  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å