# rag/retriever.py
from pathlib import Path
import chromadb
from chromadb.config import Settings
from typing import List, Dict, Any, Optional
import json

BASE_DIR = Path(__file__).resolve().parent.parent
PERSIST_DIR = BASE_DIR / "chroma_db"
COLLECTION_NAME = "interprep_knowledge"

# –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–¥–µ–π—Å—Ç–≤–∏—è
_vectorstore = None


def get_vectorstore():
    """–ü–æ–ª—É—á–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    global _vectorstore

    if _vectorstore is None:
        if not PERSIST_DIR.exists():
            raise FileNotFoundError(
                f"–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {PERSIST_DIR}.\n"
                f"–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python rag/ingest.py"
            )

        client = chromadb.PersistentClient(
            path=str(PERSIST_DIR),
            settings=Settings(anonymized_telemetry=False)
        )

        try:
            _vectorstore = client.get_collection(COLLECTION_NAME)
        except:
            raise ValueError(
                f"–ö–æ–ª–ª–µ–∫—Ü–∏—è '{COLLECTION_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\n"
                f"–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python rag/ingest.py"
            )

    return _vectorstore


def retrieve_context(
        query: str,
        k: int = 3,
        filter_by: Optional[Dict] = None,
        agent: Optional[str] = None
) -> List[str]:
    """
    –ò—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        filter_by: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        agent: –ò–º—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

    Returns:
        –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    try:
        vs = get_vectorstore()

        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –∞–≥–µ–Ω—Ç—É –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        where_filter = filter_by or {}
        if agent:
            where_filter["agent"] = agent

        results = vs.query(
            query_texts=[query],
            n_results=k,
            where=where_filter if where_filter else None,
            include=["documents", "metadatas"]
        )

        if results and results['documents']:
            return results['documents'][0]
        return []

    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {e}")
        return []


def retrieve_for_agent(agent_name: str, query: str, k: int = 3) -> List[str]:
    """
    –ò—â–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    """
    # –ú–∞–ø–ø–∏–Ω–≥ –∞–≥–µ–Ω—Ç–æ–≤ –∫ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    agent_to_type = {
        "interviewer": "interview_question",
        "reviewer": "code_example",
        "planner": "learning_plan",
        "assessor": "interview_question",  # assessor —Ç–æ–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–æ–ø—Ä–æ—Å—ã
    }

    doc_type = agent_to_type.get(agent_name)
    filter_by = {"type": doc_type} if doc_type else None

    return retrieve_context(query, k, filter_by, agent_name)


def get_questions_by_topic(topic: str, difficulty: Optional[str] = None, limit: int = 5) -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–º–µ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
    try:
        vs = get_vectorstore()

        where_filter = {
            "type": "interview_question",
            "topic": topic
        }

        if difficulty:
            where_filter["difficulty"] = difficulty

        results = vs.query(
            query_texts=[topic],
            n_results=limit,
            where=where_filter,
            include=["documents", "metadatas"]
        )

        questions = []
        if results and results['documents']:
            for doc, meta in zip(results['documents'][0], results['metadatas'][0]):
                # –ü–∞—Ä—Å–∏–º –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
                lines = doc.split('\n')
                question = ""
                answer = ""

                for line in lines:
                    if line.startswith("–í–æ–ø—Ä–æ—Å:"):
                        question = line.replace("–í–æ–ø—Ä–æ—Å:", "").strip()
                    elif line.startswith("–û—Ç–≤–µ—Ç:"):
                        answer = line.replace("–û—Ç–≤–µ—Ç:", "").strip()

                if question and answer:
                    questions.append({
                        "question": question,
                        "answer": answer,
                        "topic": meta.get("topic", ""),
                        "difficulty": meta.get("difficulty", ""),
                        "level": meta.get("level", ""),
                        "metadata": meta
                    })

        return questions

    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤: {e}")
        return []


def build_prompt_with_context(question: str, context_chunks: List[str], agent: str = None) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        context_chunks: –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        agent: –ò–º—è –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∫–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞

    Returns:
        –ì–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
    """
    if not context_chunks:
        return question

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context_lines = []
    for i, chunk in enumerate(context_chunks, 1):
        context_lines.append(f"[–ö–æ–Ω—Ç–µ–∫—Å—Ç {i}]")
        context_lines.append(chunk)
        context_lines.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞–º–∏

    context = "\n".join(context_lines).strip()

    # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
    base_prompt = f"""–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∏–∂–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {question}

–û–¢–í–ï–¢:"""

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
    agent_prompts = {
        "interviewer": f"""–¢—ã ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤.

–ö–û–ù–¢–ï–ö–°–¢ (—Ä–µ–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã —Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π):
{context}

–í–û–ü–†–û–°: {question}

–û–¢–í–ï–¢ –ò–ù–¢–ï–†–í–¨–Æ–ï–†–ê:""",

        "reviewer": f"""–¢—ã ‚Äî code reviewer. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞.

–ö–û–ù–¢–ï–ö–°–¢ (–ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞):
{context}

–ö–û–î –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê: {question}

–†–ï–í–¨–Æ:""",

        "planner": f"""–¢—ã ‚Äî –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –æ–±—É—á–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–ª–∞–Ω–æ–≤.

–ö–û–ù–¢–ï–ö–°–¢ (–ø–ª–∞–Ω—ã –æ–±—É—á–µ–Ω–∏—è –∏ —Ä–µ—Å—É—Ä—Å—ã):
{context}

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {question}

–ü–õ–ê–ù –û–ë–£–ß–ï–ù–ò–Ø:""",

        "assessor": f"""–¢—ã ‚Äî –æ—Ü–µ–Ω—â–∏–∫ –∑–Ω–∞–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤.

–ö–û–ù–¢–ï–ö–°–¢ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏):
{context}

–û–¢–í–ï–¢ –ö–ê–ù–î–ò–î–ê–¢–ê: {question}

–û–¶–ï–ù–ö–ê:"""
    }

    return agent_prompts.get(agent, base_prompt)


def check_database_status() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    try:
        vs = get_vectorstore()
        count = vs.count()

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º
        results = vs.get(include=["metadatas"])
        types_count = {}
        agents_count = {}

        if results and results["metadatas"]:
            for meta in results["metadatas"]:
                doc_type = meta.get("type", "unknown")
                agent = meta.get("agent", "unknown")

                types_count[doc_type] = types_count.get(doc_type, 0) + 1
                agents_count[agent] = agents_count.get(agent, 0) + 1

        return {
            "status": "ready",
            "documents_count": count,
            "types": types_count,
            "agents": agents_count,
            "path": str(PERSIST_DIR)
        }

    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "path": str(PERSIST_DIR),
            "exists": PERSIST_DIR.exists()
        }


# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
if __name__ == "__main__":
    print("üîç –¢–µ—Å—Ç–∏—Ä—É—é RAG —Å–∏—Å—Ç–µ–º—É...")

    status = check_database_status()
    print(f"–°—Ç–∞—Ç—É—Å: {status.get('status', 'unknown')}")

    if status["status"] == "ready":
        print(f"üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {status['documents_count']}")

        # –¢–µ—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
        agents = ["interviewer", "reviewer", "planner", "assessor"]

        for agent in agents:
            print(f"\nüß† {agent.upper()}:")
            test_query = "Python" if agent != "planner" else "–æ–±—É—á–µ–Ω–∏–µ"
            results = retrieve_for_agent(agent, test_query, k=1)

            if results:
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {results[0][:80]}...")
            else:
                print(f"   ‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {status.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
        print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python rag/ingest.py")